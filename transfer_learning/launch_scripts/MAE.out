MAE_256_20x_texture_pretrained_frozen_vote STARTED
DATA LOADED
MODEL LOADED
STEPS_PER_EPOCH: 111
VALIDATION STEPS: 13
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:13<?, ?it/s]
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 145, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_20x_texture_pretrained_frozen_novote STARTED
DATA LOADED
MODEL LOADED
STEPS_PER_EPOCH: 111
VALIDATION STEPS: 13
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:14<?, ?it/s]
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 145, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_20x_texture_pretrained_unfrozen_vote STARTED
DATA LOADED
MODEL LOADED
STEPS_PER_EPOCH: 111
VALIDATION STEPS: 13
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:12<?, ?it/s]
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 145, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_20x_texture_pretrained_unfrozen_novote STARTED
DATA LOADED
MODEL LOADED
STEPS_PER_EPOCH: 111
VALIDATION STEPS: 13
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:13<?, ?it/s]
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 145, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_20x_heightmap_pretrained_frozen_vote STARTED
DATA LOADED
MODEL LOADED
STEPS_PER_EPOCH: 111
VALIDATION STEPS: 13
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:13<?, ?it/s]
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 145, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_20x_heightmap_pretrained_frozen_novote STARTED
DATA LOADED
MODEL LOADED
STEPS_PER_EPOCH: 111
VALIDATION STEPS: 13
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:13<?, ?it/s]
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 145, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_20x_heightmap_pretrained_unfrozen_vote STARTED
DATA LOADED
MODEL LOADED
STEPS_PER_EPOCH: 111
VALIDATION STEPS: 13
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:13<?, ?it/s]
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 145, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_20x_heightmap_pretrained_unfrozen_novote STARTED
DATA LOADED
MODEL LOADED
STEPS_PER_EPOCH: 111
VALIDATION STEPS: 13
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:13<?, ?it/s]
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 145, in train
    print(y.shape)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_50x_texture_pretrained_frozen_vote STARTED
DATA LOADED
MODEL LOADED
STEPS_PER_EPOCH: 44
VALIDATION STEPS: 5
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:12<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 146, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_50x_texture_pretrained_frozen_novote STARTED
DATA LOADED
MODEL LOADED
STEPS_PER_EPOCH: 44
VALIDATION STEPS: 5
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:13<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 146, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_50x_texture_pretrained_unfrozen_vote STARTED
DATA LOADED
MODEL LOADED
STEPS_PER_EPOCH: 44
VALIDATION STEPS: 5
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:11<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 146, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_50x_texture_pretrained_unfrozen_novote STARTED
DATA LOADED
MODEL LOADED
STEPS_PER_EPOCH: 44
VALIDATION STEPS: 5
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:12<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 146, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_50x_heightmap_pretrained_frozen_vote STARTED
DATA LOADED
MODEL LOADED
STEPS_PER_EPOCH: 44
VALIDATION STEPS: 5
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:13<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 146, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_50x_heightmap_pretrained_frozen_novote STARTED
DATA LOADED
MODEL LOADED
STEPS_PER_EPOCH: 44
VALIDATION STEPS: 5
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:12<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 146, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_50x_heightmap_pretrained_unfrozen_vote STARTED
DATA LOADED
MODEL LOADED
STEPS_PER_EPOCH: 44
VALIDATION STEPS: 5
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:12<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 146, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_50x_heightmap_pretrained_unfrozen_novote STARTED
DATA LOADED
MODEL LOADED
STEPS_PER_EPOCH: 44
VALIDATION STEPS: 5
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:12<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 146, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_20x+50x_texture_pretrained_frozen_vote STARTED
DATA LOADED
MODEL LOADED
STEPS_PER_EPOCH: 71
VALIDATION STEPS: 8
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:12<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 146, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_20x+50x_texture_pretrained_frozen_novote STARTED
DATA LOADED
MODEL LOADED
STEPS_PER_EPOCH: 71
VALIDATION STEPS: 8
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:13<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 146, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_20x+50x_texture_pretrained_unfrozen_vote STARTED
DATA LOADED
MODEL LOADED
STEPS_PER_EPOCH: 71
VALIDATION STEPS: 8
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:10<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 146, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_20x+50x_texture_pretrained_unfrozen_novote STARTED
DATA LOADED
MODEL LOADED
STEPS_PER_EPOCH: 71
VALIDATION STEPS: 8
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:12<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 146, in train
    print(y.shape)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_20x+50x_heightmap_pretrained_frozen_vote STARTED
DATA LOADED
MaskedAutoencoderViT(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-23): 24 x Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
  (decoder_blocks): ModuleList(
    (0-7): 8 x Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (decoder_pred): Linear(in_features=512, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 71
VALIDATION STEPS: 8
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:13<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_20x+50x_heightmap_pretrained_frozen_novote STARTED
DATA LOADED
MaskedAutoencoderViT(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-23): 24 x Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
  (decoder_blocks): ModuleList(
    (0-7): 8 x Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (decoder_pred): Linear(in_features=512, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 71
VALIDATION STEPS: 8
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:14<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_20x+50x_heightmap_pretrained_unfrozen_vote STARTED
DATA LOADED
MaskedAutoencoderViT(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-23): 24 x Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
  (decoder_blocks): ModuleList(
    (0-7): 8 x Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (decoder_pred): Linear(in_features=512, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 71
VALIDATION STEPS: 8
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:13<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_256_20x+50x_heightmap_pretrained_unfrozen_novote STARTED
DATA LOADED
MaskedAutoencoderViT(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-23): 24 x Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
  (decoder_blocks): ModuleList(
    (0-7): 8 x Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (decoder_pred): Linear(in_features=512, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 71
VALIDATION STEPS: 8
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:13<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_20x_texture_pretrained_frozen_vote STARTED
DATA LOADED
MaskedAutoencoderViT(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-23): 24 x Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
  (decoder_blocks): ModuleList(
    (0-7): 8 x Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (decoder_pred): Linear(in_features=512, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 14
VALIDATION STEPS: 2
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:13<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_20x_texture_pretrained_frozen_novote STARTED
DATA LOADED
MaskedAutoencoderViT(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-23): 24 x Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
  (decoder_blocks): ModuleList(
    (0-7): 8 x Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (decoder_pred): Linear(in_features=512, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 14
VALIDATION STEPS: 2
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:10<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_20x_texture_pretrained_unfrozen_vote STARTED
DATA LOADED
MaskedAutoencoderViT(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-23): 24 x Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
  (decoder_blocks): ModuleList(
    (0-7): 8 x Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (decoder_pred): Linear(in_features=512, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 14
VALIDATION STEPS: 2
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:08<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_20x_texture_pretrained_unfrozen_novote STARTED
DATA LOADED
MaskedAutoencoderViT(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-23): 24 x Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
  (decoder_blocks): ModuleList(
    (0-7): 8 x Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (decoder_pred): Linear(in_features=512, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 14
VALIDATION STEPS: 2
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:07<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_20x_heightmap_pretrained_frozen_vote STARTED
DATA LOADED
MaskedAutoencoderViT(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-23): 24 x Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
  (decoder_blocks): ModuleList(
    (0-7): 8 x Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (decoder_pred): Linear(in_features=512, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 14
VALIDATION STEPS: 2
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:11<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_20x_heightmap_pretrained_frozen_novote STARTED
DATA LOADED
MaskedAutoencoderViT(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-23): 24 x Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
  (decoder_blocks): ModuleList(
    (0-7): 8 x Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (decoder_pred): Linear(in_features=512, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 14
VALIDATION STEPS: 2
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:11<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_20x_heightmap_pretrained_unfrozen_vote STARTED
DATA LOADED
MaskedAutoencoderViT(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-23): 24 x Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
  (decoder_blocks): ModuleList(
    (0-7): 8 x Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (decoder_pred): Linear(in_features=512, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 14
VALIDATION STEPS: 2
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:11<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_20x_heightmap_pretrained_unfrozen_novote STARTED
DATA LOADED
MaskedAutoencoderViT(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-23): 24 x Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
  (decoder_blocks): ModuleList(
    (0-7): 8 x Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (decoder_pred): Linear(in_features=512, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 14
VALIDATION STEPS: 2
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:11<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_50x_texture_pretrained_frozen_vote STARTED
DATA LOADED
MaskedAutoencoderViT(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-23): 24 x Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
  (decoder_blocks): ModuleList(
    (0-7): 8 x Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (decoder_pred): Linear(in_features=512, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 8
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:12<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_50x_texture_pretrained_frozen_novote STARTED
DATA LOADED
MaskedAutoencoderViT(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-23): 24 x Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
  (decoder_blocks): ModuleList(
    (0-7): 8 x Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (decoder_pred): Linear(in_features=512, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 8
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:12<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_50x_texture_pretrained_unfrozen_vote STARTED
DATA LOADED
MaskedAutoencoderViT(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-23): 24 x Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
  (decoder_blocks): ModuleList(
    (0-7): 8 x Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (decoder_pred): Linear(in_features=512, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 8
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:08<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_50x_texture_pretrained_unfrozen_novote STARTED
DATA LOADED
MaskedAutoencoderViT(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-23): 24 x Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
  (decoder_blocks): ModuleList(
    (0-7): 8 x Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (decoder_pred): Linear(in_features=512, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 8
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:09<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_50x_heightmap_pretrained_frozen_vote STARTED
DATA LOADED
MaskedAutoencoderViT(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-23): 24 x Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
  (decoder_blocks): ModuleList(
    (0-7): 8 x Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (decoder_pred): Linear(in_features=512, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 8
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:15<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_50x_heightmap_pretrained_frozen_novote STARTED
DATA LOADED
MaskedAutoencoderViT(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-23): 24 x Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
  (decoder_blocks): ModuleList(
    (0-7): 8 x Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (decoder_pred): Linear(in_features=512, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 8
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:13<?, ?it/s]
torch.Size([100, 196, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_50x_heightmap_pretrained_unfrozen_vote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 8
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:12<?, ?it/s]
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_50x_heightmap_pretrained_unfrozen_novote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 8
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:10<?, ?it/s]
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_20x+50x_texture_pretrained_frozen_vote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 11
VALIDATION STEPS: 2
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:10<?, ?it/s]
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_20x+50x_texture_pretrained_frozen_novote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 11
VALIDATION STEPS: 2
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:09<?, ?it/s]
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_20x+50x_texture_pretrained_unfrozen_vote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 11
VALIDATION STEPS: 2
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:08<?, ?it/s]
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_20x+50x_texture_pretrained_unfrozen_novote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 11
VALIDATION STEPS: 2
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:07<?, ?it/s]
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_20x+50x_heightmap_pretrained_frozen_vote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 11
VALIDATION STEPS: 2
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:11<?, ?it/s]
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_20x+50x_heightmap_pretrained_frozen_novote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 11
VALIDATION STEPS: 2
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:09<?, ?it/s]
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_20x+50x_heightmap_pretrained_unfrozen_vote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 11
VALIDATION STEPS: 2
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:08<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_512_20x+50x_heightmap_pretrained_unfrozen_novote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 11
VALIDATION STEPS: 2
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:08<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_20x_texture_pretrained_frozen_vote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:09<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_20x_texture_pretrained_frozen_novote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:08<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_20x_texture_pretrained_unfrozen_vote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:09<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_20x_texture_pretrained_unfrozen_novote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:09<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_20x_heightmap_pretrained_frozen_vote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:12<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_20x_heightmap_pretrained_frozen_novote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:11<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_20x_heightmap_pretrained_unfrozen_vote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:10<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_20x_heightmap_pretrained_unfrozen_novote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:09<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_50x_texture_pretrained_frozen_vote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:10<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_50x_texture_pretrained_frozen_novote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:09<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_50x_texture_pretrained_unfrozen_vote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:10<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_50x_texture_pretrained_unfrozen_novote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:12<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_50x_heightmap_pretrained_frozen_vote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:12<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_50x_heightmap_pretrained_frozen_novote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:11<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_50x_heightmap_pretrained_unfrozen_vote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:10<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_50x_heightmap_pretrained_unfrozen_novote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:10<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_20x+50x_texture_pretrained_frozen_vote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:12<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_20x+50x_texture_pretrained_frozen_novote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:12<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_20x+50x_texture_pretrained_unfrozen_vote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:10<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_20x+50x_texture_pretrained_unfrozen_novote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:13<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_20x+50x_heightmap_pretrained_frozen_vote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:12<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_20x+50x_heightmap_pretrained_frozen_novote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:12<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_20x+50x_heightmap_pretrained_unfrozen_vote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:12<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
MAE_865_20x+50x_heightmap_pretrained_unfrozen_novote STARTED
DATA LOADED
Sequential(
  (0): MaskedAutoencoderViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)
    (decoder_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
  )
  (1): Linear(in_features=1024, out_features=6, bias=True)
)
MODEL LOADED
STEPS_PER_EPOCH: 3
VALIDATION STEPS: 1
SETUP DONE
TRAINING STARTED
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:10<?, ?it/s]
torch.Size([100, 50, 1024])
torch.Size([100, 50, 6])
torch.Size([100])
Traceback (most recent call last):
  File "dl_supervised_pipeline.py", line 158, in <module>
    main(args)
  File "dl_supervised_pipeline.py", line 123, in main
    train_loss, train_acc_1, train_acc_3 = train(model, train_iterator, optimizer, criterion, scheduler, device)
  File "/scratch/zf540/LUWA/workspace/utils/experiment_utils.py", line 147, in train
    loss = criterion(y_pred, y)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/ext3/EgoPAT3Dv2/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [100, 6], got [100]
